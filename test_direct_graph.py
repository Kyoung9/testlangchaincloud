#!/usr/bin/env python3
"""LangGraphë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸"""

import asyncio
import os
from dotenv import load_dotenv
from src.agent.graph import invoke_graph, InputSchema, Configuration

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

async def test_direct_graph():
    """LangGraphë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ LangGraph ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: city_hint ì‚¬ìš©
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ 1: city_hint ì‚¬ìš©")
    input1 = InputSchema(
        messages=[{"role": "user", "content": "ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?"}],
        city="Tokyo"
    )
    config1 = Configuration(
        openai_api_key=os.getenv("OPENAI_API_KEY", ""),
        api_key=os.getenv("OPENWEATHER_API_KEY", "")
    )
    
    result1 = await invoke_graph(input1, config1)
    print(f"ê²°ê³¼ 1: {result1}")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ìì—°ì–´ì—ì„œ ë„ì‹œëª… ì¶”ì¶œ
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ 2: ìì—°ì–´ì—ì„œ ë„ì‹œëª… ì¶”ì¶œ")
    input2 = InputSchema(
        messages=[{"role": "user", "content": "ë„ì¿„ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?"}]
    )
    config2 = Configuration(
        openai_api_key=os.getenv("OPENAI_API_KEY", ""),
        api_key=os.getenv("OPENWEATHER_API_KEY", "")
    )
    
    result2 = await invoke_graph(input2, config2)
    print(f"ê²°ê³¼ 2: {result2}")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ì—ëŸ¬ ì¼€ì´ìŠ¤ (API í‚¤ ì—†ìŒ)
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ 3: ì—ëŸ¬ ì¼€ì´ìŠ¤ (API í‚¤ ì—†ìŒ)")
    input3 = InputSchema(
        messages=[{"role": "user", "content": "ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?"}],
        city="Seoul"
    )
    
    result3 = await invoke_graph(input3)
    print(f"ê²°ê³¼ 3: {result3}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        await test_direct_graph()
        print("\nâœ¨ ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 